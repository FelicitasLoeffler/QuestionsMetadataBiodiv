<data><id>oai:v1.datadryad.org:10255/dryad.177299</id><oai_dc:dc/dc:title>Data from: Creating a multi-track classical music performance dataset for multi-modal music analysis: challenges, insights, and applications</oai_dc:dc/dc:title><oai_dc:dc/dc:description>We introduce a dataset for facilitating audio-visual analysis of musical performances. The dataset comprises 44 simple multi-instrument classical music pieces assembled from coordinated but separately recorded performances of individual tracks. For each piece, we provide the musical score in MIDI format, the audio recordings of the individual tracks, the audio and video recording of the assembled mixture, and ground- truth annotation files including frame-level and note-level tran- scriptions. We describe our methodology for the creation of the dataset, particularly highlighting our approaches for addressing the challenges involved in maintaining synchronization and ex- pressiveness. We demonstrate the high quality of synchronization achieved with our proposed approach by comparing the dataset against existing widely-used music audio datasets. We anticipate that the dataset will be useful for the devel- opment and evaluation of existing music information retrieval (MIR) tasks, as well as for novel multi-modal tasks. We bench- mark two existing MIR tasks (multi-pitch analysis and score- informed source separation) on the dataset and compare against other existing music audio datasets. Additionally, we consider two novel multi-modal MIR tasks (visually informed multi-pitch analysis and polyphonic vibrato analysis) enabled by the dataset and provide evaluation measures and baseline systems for future comparisons (from our recent work). Finally, we propose several emerging research directions that the dataset enables.</oai_dc:dc/dc:description><oai_dc:dc/dc:subject>Multi-modal music dataset|audio-visual analysis|music performance|synchronization</oai_dc:dc/dc:subject><date
>2018-06-20T11:24:49Z</date
></data>